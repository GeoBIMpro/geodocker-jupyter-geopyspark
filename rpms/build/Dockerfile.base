FROM amazonlinux:2016.09.1.20161221
MAINTAINER James McClain <james.mcclain@gmail.com>

# Java
RUN yum update -y
RUN yum install -y java-1.8.0-openjdk

# Spark
ENV SPARK_HOME /usr/local/spark-2.1.0-bin-hadoop2.7
ADD blobs/spark-2.1.0-bin-hadoop2.7.tgz /usr/local
RUN ln -s /usr/local/spark-2.1.0-bin-hadoop2.7 /usr/local/spark

# GDAL and friends
COPY blobs/gdal-and-friends.tar.gz /blobs/

# kit, caboodle
COPY rpmbuild/RPMS/x86_64/boost162-lib-1_62_0-33.x86_64.rpm /rpms/
COPY rpmbuild/RPMS/x86_64/freetype2-lib-2.8-33.x86_64.rpm /rpms/
COPY rpmbuild/RPMS/x86_64/gcc6-lib-6.4.0-33.x86_64.rpm /rpms/
COPY rpmbuild/RPMS/x86_64/gdal213-2.1.3-33.x86_64.rpm /rpms/
COPY rpmbuild/RPMS/x86_64/jupyterhub-0.7.2-13.x86_64.rpm /rpms/
COPY rpmbuild/RPMS/x86_64/mapnik-093fcee-33.x86_64.rpm /rpms/
COPY rpmbuild/RPMS/x86_64/nodejs-8.5.0-13.x86_64.rpm /rpms/
COPY rpmbuild/RPMS/x86_64/proj493-lib-4.9.3-33.x86_64.rpm /rpms/
COPY rpmbuild/RPMS/x86_64/python-mapnik-e5f107d-33.x86_64.rpm /rpms/
RUN yum localinstall -y /rpms/*.rpm && \
    echo /usr/local/lib >> /etc/ld.so.conf.d/local.conf && echo /usr/local/lib64 >> /etc/ld.so.conf.d/local.conf && \
    ldconfig

# Create user
RUN yum install -y shadow-utils && \
    useradd hadoop -m && usermod -a -G root hadoop && (echo 'hadoop:hadoop' | chpasswd)

# Misc
RUN yum install -y unzip python34 pam
RUN curl https://bootstrap.pypa.io/get-pip.py | python3.4
RUN ln -s /usr/local/share/jupyter /usr/share/jupyter
COPY etc/pam.d/login /etc/pam.d/login

USER hadoop
